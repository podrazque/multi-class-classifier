{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from files...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"HMP_Dataset\"\n",
    "TRAINING_SETS = np.array(['Use_telephone', 'Standup_chair', 'Walk', 'Climb_stairs', 'Sitdown_chair', 'Brush_teeth', 'Comb_hair', 'Eat_soup', 'Pour_water', 'Descend_stairs', 'Eat_meat', 'Drink_glass', 'Getup_bed', 'Liedown_bed'])\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "print(\"Reading data from files...\")\n",
    "\n",
    "def initial_setup():\n",
    "    for dataset in TRAINING_SETS:\n",
    "        all_data[dataset] = []\n",
    "        for f in listdir(join(DATASET_DIR, dataset)):\n",
    "            all_data[dataset].append(np.array(np.genfromtxt(join(DATASET_DIR, dataset, f), usecols=(0, 1, 2))))\n",
    "        all_data[dataset] = np.array(all_data[dataset])\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockshaped(arr, nrows, ncols):\n",
    "    h, w = arr.shape\n",
    "    return (arr.reshape(h//nrows, nrows, -1, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, nrows, ncols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(chunk_me):\n",
    "    dif = chunk_me.shape[0]%32\n",
    "    chunk_me = chunk_me[dif:,:]\n",
    "    chunk_me = blockshaped(chunk_me, 32, 3)\n",
    "    return chunk_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_setup()\n",
    "chunkified_data = all_data\n",
    "for k in TRAINING_SETS:\n",
    "    for i in range(len(all_data[k])):\n",
    "        chunkified_data[k][i] = chunkify(all_data[k][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = chunkified_data\n",
    "flat_stuff = {}\n",
    "for k in TRAINING_SETS:\n",
    "    flat_stuff[k] = []\n",
    "    for j in range(len(flattened_data[k])):\n",
    "        for i in range(len(flattened_data[k][j])):\n",
    "            flat_stuff[k].append(flattened_data[k][j][i].reshape(1,96))\n",
    "    flat_stuff[k] = np.asarray(flat_stuff[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
